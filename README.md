 # NLP

Keyword Extraction,
POS Tagging,
Parsing,
Named Entity Recognition,
Relationship extraction,
Information Retrieval,
Sentimental Classification

Ultimate Guide to Understand & Implement Natural Language Processing
https://www.analyticsvidhya.com/blog/2017/01/ultimate-guide-to-understand-implement-natural-language-processing-codes-in-python/

# Tokenization:

_Tokenization is a way to split text into tokens. These tokens could be paragraphs, sentences, or individual words.

_Word tokenization is the process of splitting a large sample of text into words. This is a requirement in natural language      processing tasks where each word needs to be captured and subjected to further analysis like classifying and counting them   for a particular sentiment etc.

_The Natural Language Tool kit(NLTK) is a library used to achieve this. you can use SpaCy as well for better performance.


# Text Preprocessing:

_text is the most unstructured form of all the available data, various types of noise are present in it and the data is not readily analyzable without any pre-processing. The entire process of cleaning and standardization of text, making it noise-free and ready for analysis is known as text preprocessing.

_ Noise Removal(Expressions,Stop_words)
  Lexicon Normalization(Stemming, lemming)
  Object Standardization(acronyms, hashtags with attached words, and colloquial slangs)
  
# Feature Engineering:

_ To analyse a preprocessed data, it needs to be converted into features. Depending upon the usage, text features can be constructed using assorted techniques â€“ Syntactical Parsing, Entities / N-grams / word-based features, Statistical features, and word embeddings.


## NER - Named Entity Recognition ##

https://medium.com/explore-artificial-intelligence/introduction-to-named-entity-recognition-eda8c97c2db1

Standford NER,
spaCy,
NLTK,
Deep Learning.




