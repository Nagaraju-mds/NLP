 # NLP

Keyword Extraction,
POS Tagging,
Parsing,
Named Entity Recognition,
Relationship extraction,
Information Retrieval,
Sentimental Classification

Ultimate Guide to Understand & Implement Natural Language Processing
https://www.analyticsvidhya.com/blog/2017/01/ultimate-guide-to-understand-implement-natural-language-processing-codes-in-python/

# Tokenization:

_Tokenization is a way to split text into tokens. These tokens could be paragraphs, sentences, or individual words.
_Word tokenization is the process of splitting a large sample of text into words. This is a requirement in natural language      processing tasks where each word needs to be captured and subjected to further analysis like classifying and counting them   for a particular sentiment etc.
_The Natural Language Tool kit(NLTK) is a library used to achieve this. you can use SpaCy as well for better performance.

